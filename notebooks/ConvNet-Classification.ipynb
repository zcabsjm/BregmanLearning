{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044d7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ------------------------\n",
    "# get up one directory \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "# ------------------------\n",
    "\n",
    "# custom packages\n",
    "import models.aux_funs as maf\n",
    "import optimizers as op\n",
    "import regularizers as reg\n",
    "import train\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.configuration as cf\n",
    "import utils.datasets as ud\n",
    "from models.mnist_conv import mnist_conv\n",
    "from scipy.interpolate import make_interp_spline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb1290",
   "metadata": {},
   "source": [
    "# Fix the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf73f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "cf.seed_torch(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1cf2a",
   "metadata": {},
   "source": [
    "# Configure the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3dd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_args = {#\n",
    "    # data specification\n",
    "    'data_file':\"../../datasets\",'train_split':0.95, 'data_set':\"Fashion-MNIST\", 'download':True,\n",
    "    # cuda\n",
    "    'use_cuda':False, 'num_workers':2, 'cuda_device':0, 'pin_memory':True, 'train_split':0.95,\n",
    "    #\n",
    "    'epochs':50,\n",
    "    # optimizer\n",
    "    'delta':1.0, 'lr':0.1, 'lamda_0':1e-4, 'lamda_1':0.01, 'optim':\"LinBreg\", 'conv_group':True,\n",
    "    'beta':0.0,\n",
    "    # initialization\n",
    "    'sparse_init':0.01, 'r':[10.,10.,10.],\n",
    "    # misc\n",
    "    'random_seed':random_seed, 'eval_acc':True,\n",
    "}\n",
    "\n",
    "conf = cf.Conf(**conf_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24fc71",
   "metadata": {},
   "source": [
    "# Initiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2a15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {'mean':conf.data_set_mean, 'std':conf.data_set_std}    \n",
    "\n",
    "model = mnist_conv(**model_kwargs)\n",
    "best_model = train.best_model(mnist_conv(**model_kwargs).to(conf.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2696003",
   "metadata": {},
   "source": [
    "# Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e2e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {'mean':conf.data_set_mean, 'std':conf.data_set_std}    \n",
    "def init_weights(conf, model):\n",
    "    # sparsify\n",
    "    maf.sparse_bias_uniform_(model, 0,conf.r[0])\n",
    "    maf.sparse_bias_uniform_(model, 0,conf.r[0], ltype=torch.nn.Conv2d)\n",
    "    maf.sparse_weight_normal_(model, conf.r[1])\n",
    "    maf.sparse_weight_normal_(model, conf.r[2], ltype=torch.nn.Conv2d)\n",
    "    #\n",
    "    maf.sparsify_(model, conf.sparse_init, ltype = nn.Conv2d, conv_group=conf.conv_group)\n",
    "    maf.sparsify_(model, conf.sparse_init, ltype = nn.Linear)\n",
    "    model = model.to(conf.device)    \n",
    "    return model\n",
    "\n",
    "model = init_weights(conf,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff0a86b",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51048c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_opt(conf, model):\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # Get access to different model parameters\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    weights_conv = maf.get_weights_conv(model)\n",
    "    weights_linear = maf.get_weights_linear(model)\n",
    "    biases = maf.get_bias(model)\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # Initialize optimizer\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    if conf.conv_group:\n",
    "        reg2 = reg.reg_l1_l2_conv(lamda=conf.lamda_0)\n",
    "    else:\n",
    "        reg2 = reg.reg_l1(lamda=conf.lamda_0)\n",
    "    \n",
    "    if conf.optim == \"SGD\":\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=conf.lr, momentum=conf.beta)\n",
    "    elif conf.optim == \"LinBreg\": # change 'reg' to reg2 if want to use l1_l2 regularization as was previously\n",
    "        opt = op.LinBreg([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg2, 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          # apply nuclear regularization to the conv layers, switch to l1 reg.reg_l1(lamda=conf.lamda_1) if needed\n",
    "                          {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_nuclear_linear_truncated(lamda=conf.lamda_1, rank=64), 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': biases, 'lr': conf.lr, 'momentum':conf.beta}])\n",
    "    elif conf.optim == \"ProxSGD\":\n",
    "        opt = op.ProxSGD([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg2, 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_nuclear_linear(lamda=conf.lamda_1), 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': biases, 'lr': conf.lr, 'momentum':conf.beta}])            \n",
    "    elif conf.optim == \"AdaBreg\":\n",
    "        opt = op.AdaBreg([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg.reg_nuclear_conv(lamda=conf.lamda_0),'delta':conf.delta},\n",
    "                           {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(lamda=conf.lamda_1),'delta':conf.delta},\n",
    "                           {'params': biases, 'lr': conf.lr}])\n",
    "    elif conf.optim == \"L1SGD\":\n",
    "        def weight_reg(model):\n",
    "            reg1 =  reg.reg_l1(lamda=conf.lamda_1)\n",
    "        \n",
    "            loss1 = reg1(model.layers2[0].weight) + reg1(model.layers2[2].weight)\n",
    "            loss2 = reg2(model.layers1[0].weight) + reg2(model.layers1[3].weight)\n",
    "            return loss1 + loss2\n",
    "        \n",
    "        conf.weight_reg = weight_reg\n",
    "        \n",
    "        opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=beta)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Optimizer specified\")\n",
    "\n",
    "    # learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=5,threshold=0.01)\n",
    "    \n",
    "    return opt, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9836a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53442c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = ud.get_data_set(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4ea23",
   "metadata": {},
   "source": [
    "# History and Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "985cdc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize history\n",
    "tracked = ['loss', 'node_sparse']\n",
    "train_hist = {}\n",
    "val_hist = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6adef",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d28eb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 0\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.1013157894736842\n",
      "Train Loss: 1162.164246082306\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.101\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6134), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.1\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 1\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.09849122807017544\n",
      "Train Loss: 1027.4421036243439\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.096\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6115), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.1\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 2\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.09873684210526316\n",
      "Train Loss: 1027.4662437438965\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.092\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6138), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.1\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 3\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.10156140350877194\n",
      "Train Loss: 1027.3539550304413\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.099\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6142), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.1\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 4\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.09857894736842106\n",
      "Train Loss: 1027.4062254428864\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.096\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6134), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.1\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 5\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.09956140350877193\n",
      "Train Loss: 1027.4037029743195\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.09966666666666667\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6130), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.1\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 6\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.10073684210526315\n",
      "Train Loss: 1027.3492612838745\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.101\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6142), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.1\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 7\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.10035087719298245\n",
      "Train Loss: 1027.3998470306396\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.101\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6121), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.05\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 8\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.09964912280701754\n",
      "Train Loss: 1027.2246565818787\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.099\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6134), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.05\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 9\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.09812280701754386\n",
      "Train Loss: 1027.2341525554657\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.10933333333333334\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6138), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.05\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 10\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.10021052631578947\n",
      "Train Loss: 1027.203382730484\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.092\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6119), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.05\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 11\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.09721052631578947\n",
      "Train Loss: 1027.2041223049164\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.096\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6143), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.05\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 12\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.09891228070175438\n",
      "Train Loss: 1027.2087361812592\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.10466666666666667\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6117), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.05\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 13\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.0992982456140351\n",
      "Train Loss: 1027.1916558742523\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.096\n",
      "Non-zero kernels: 0.8533653846153846\n",
      "Linear sparsity: 0.9642166344294004\n",
      "Overall sparsity: 0.9154396831844029\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [0.15871940231323242, tensor(2.6130), 0.0]\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.5000\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0000\n",
      "Test Accuracy: 0.1000\n",
      "Learning rate: 0.025\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x10a902200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shyammodi/miniforge3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/shyammodi/miniforge3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1568, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/shyammodi/miniforge3/lib/python3.12/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shyammodi/miniforge3/lib/python3.12/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shyammodi/miniforge3/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shyammodi/miniforge3/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shyammodi/miniforge3/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 29842) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# train step, log the accuracy and loss\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# update history\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m tracked:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Documents/University Year 4/Final Year Project/Seminal Paper Code/BregmanLearning/train.py:15\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(conf, model, opt, train_loader, verbosity)\u001b[0m\n\u001b[1;32m     13\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(conf\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(conf\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     14\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mloss(logits, y)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conf,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Documents/University Year 4/Final Year Project/Seminal Paper Code/BregmanLearning/models/mnist_conv.py:45\u001b[0m, in \u001b[0;36mmnist_conv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     44\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd\n\u001b[0;32m---> 45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers2(x)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# Reinit weights and the corresponding optimizer\n",
    "# -----------------------------------------------------------------------------------\n",
    "model = init_weights(conf, model)\n",
    "opt, scheduler = init_opt(conf, model)\n",
    "\n",
    "# Initialize history for tracking both metrics\n",
    "effective_rank_histories = {}  # Dictionary to store rank history for each layer\n",
    "test_accuracy_history = []\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# train the model\n",
    "# -----------------------------------------------------------------------------------\n",
    "for epoch in range(conf.epochs):\n",
    "    print(25*\"<>\")\n",
    "    print(50*\"|\")\n",
    "    print(25*\"<>\")\n",
    "    print('Epoch:', epoch)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # train step, log the accuracy and loss\n",
    "    # ------------------------------------------------------------------------\n",
    "    train_data = train.train_step(conf, model, opt, train_loader)\n",
    "\n",
    "    # update history\n",
    "    for key in tracked:\n",
    "        if key in train_data:\n",
    "            var_list = train_hist.setdefault(key, [])\n",
    "            var_list.append(train_data[key])           \n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # validation step\n",
    "    # ------------------------------------------------------------------------\n",
    "    val_data = train.validation_step(conf, model, opt, valid_loader)\n",
    "\n",
    "    # update validation history\n",
    "    for key in tracked:\n",
    "        if key in val_data:\n",
    "            var = val_data[key]\n",
    "            if isinstance(var, list):\n",
    "                for i, var_loc in enumerate(var):\n",
    "                    key_loc = key+\"_\" + str(i)\n",
    "                    var_list = val_hist.setdefault(key_loc, [])\n",
    "                    val_hist[key_loc].append(var_loc)\n",
    "            else:\n",
    "                var_list = val_hist.setdefault(key, [])\n",
    "                var_list.append(var)   \n",
    "\n",
    "    # Track effective rank ratio for each FC layer separately\n",
    "    fc_layer_ranks = maf.get_linear_layer_ranks(model, epsilon=1e-3)\n",
    "    for layer_name, rank_ratio in fc_layer_ranks.items():\n",
    "        if layer_name not in effective_rank_histories:\n",
    "            effective_rank_histories[layer_name] = []\n",
    "        effective_rank_histories[layer_name].append(rank_ratio)\n",
    "        print(f'Layer {layer_name} rank ratio (ε=1e-3): {rank_ratio:.4f}')\n",
    "    \n",
    "    # Also track test accuracy each epoch\n",
    "    test_data = train.test(conf, model, test_loader, verbosity=0)\n",
    "    test_accuracy_history.append(test_data['acc'])\n",
    "    print(f'Test Accuracy: {test_data[\"acc\"]:.4f}')\n",
    "\n",
    "    scheduler.step(train_data['loss'])\n",
    "    print(\"Learning rate:\", opt.param_groups[0]['lr'])\n",
    "    best_model(train_data['acc'], val_data['acc'], model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabbb46d-724c-4d45-a7b3-c5bfef8a3f03",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c82a0-6940-4c33-bcb2-c4b2ab56171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Test Accuracy: 0.1\n",
      "Convolution kernel sparsity: 0.8117788461538461\n",
      "Linear sparsity: 0.9564796905222437\n",
      "Linear Layer Effective Rank Ratio (ε=1e-3): 0.5390625\n",
      "Layer layers2.0 rank ratio (ε=1e-3): 0.078125\n",
      "Layer layers2.2 rank ratio (ε=1e-3): 1.0\n",
      "\n",
      "Singular values of linear layers:\n",
      "Layer layers2.0 singular values: tensor([12.4662,  7.0135,  5.5737,  4.8671,  2.9138,  2.1090,  2.0824,  2.0061,\n",
      "         1.9433,  1.8215], grad_fn=<SliceBackward0>)\n",
      "Layer layers2.2 singular values: tensor([14.9471,  3.9605,  2.4626,  1.1551,  0.9175,  0.8149,  0.4832,  0.4682,\n",
      "         0.1248,  0.0744], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train.test(conf, best_model.best_model, test_loader) \n",
    "print(f'Convolution kernel sparsity: {maf.conv_sparsity(best_model.best_model)}')\n",
    "print(f'Linear sparsity: {maf.linear_sparsity(best_model.best_model)}')\n",
    "linear_rank_ratio = maf.linear_effective_rank_ratio(best_model.best_model, epsilon=1e-3)\n",
    "print(f'Linear Layer Effective Rank Ratio (ε=1e-3): {linear_rank_ratio}')\n",
    "fc_layer_ranks = maf.get_linear_layer_ranks(best_model.best_model, epsilon=1e-3)\n",
    "for layer_name, rank_ratio in fc_layer_ranks.items():\n",
    "    print(f'Layer {layer_name} rank ratio (ε=1e-3): {fc_layer_ranks[layer_name]}')\n",
    "print(\"\\nSingular values of linear layers:\")\n",
    "for name, m in best_model.best_model.named_modules():\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        _, S, _ = torch.svd(m.weight, some=True)\n",
    "        print(f\"Layer {name} singular values: {S[:10]}\")  # Show first 10 values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2fc4af",
   "metadata": {},
   "source": [
    "# Setup plots and appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85994ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rcParams['font.size']=8\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "matplotlib.rcParams['lines.markersize'] = 2\n",
    "matplotlib.rcParams['text.color'] = 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af623214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 687.634x401.389 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure with 1x2 subplots (rank ratio and accuracy)\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax = np.ravel(ax)  # Convert to 1D array for consistent indexing\n",
    "\n",
    "# Create arrays for plotting\n",
    "x = np.array(range(conf.epochs))\n",
    "\n",
    "# Dictionary to map layer names to more descriptive labels\n",
    "layer_display_names = {\n",
    "    'layers2.0': 'FCC 1 (1024→128)',  # First fully connected layer\n",
    "    'layers2.2': 'FCC 2 (128→10)'     # Second fully connected layer\n",
    "}\n",
    "\n",
    "# Plot effective rank ratio for each layer in first subplot - different colors\n",
    "colors = ['blue', 'green', 'purple', 'orange', 'brown', 'pink']\n",
    "for i, (layer_name, history) in enumerate(effective_rank_histories.items()):\n",
    "    color = colors[i % len(colors)]\n",
    "    # Get descriptive name or use original if not in the dictionary\n",
    "    display_name = layer_display_names.get(layer_name, layer_name)\n",
    "    # Convert to percentage\n",
    "    history_percent = [val * 100 for val in history]\n",
    "    ax[0].plot(x, history_percent, linestyle='-', color=color, label=f'{display_name} Rank Ratio')\n",
    "    ax[0].scatter(x, history_percent, color=color, s=20, alpha=0.5)\n",
    "\n",
    "# Plot test accuracy in second subplot - as before\n",
    "# Convert to percentage\n",
    "test_accuracy_percent = [acc * 100 for acc in test_accuracy_history]\n",
    "ax[1].plot(x, test_accuracy_percent, linestyle='--', color='red', label='Test Accuracy')\n",
    "ax[1].scatter(x, test_accuracy_percent, color='red', s=20, alpha=0.5)\n",
    "\n",
    "# Specify axes\n",
    "## Effective Rank Ratio\n",
    "ax[0].set_ylabel('Effective Rank Ratio [%]')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "## Test Accuracy\n",
    "ax[1].set_ylabel('Test Accuracy [%]')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Modify x-axis to show labels at multiples of 5 for both subplots\n",
    "max_epoch = len(x) - 1\n",
    "xticks = [i for i in range(0, max_epoch+1, 5)]\n",
    "if max_epoch not in xticks:\n",
    "    xticks.append(max_epoch)\n",
    "ax[0].set_xticks(xticks)\n",
    "ax[1].set_xticks(xticks)\n",
    "\n",
    "# Get legend handles from both plots\n",
    "handles = []\n",
    "labels = []\n",
    "for i in range(len(ax)):\n",
    "    h, l = ax[i].get_legend_handles_labels()\n",
    "    handles.extend(h)\n",
    "    labels.extend(l)\n",
    "\n",
    "# Add a legend to the first subplot but position it outside\n",
    "ax[0].legend(handles, labels, loc='upper left', bbox_to_anchor=(1.05, 1), prop={'size': 6}, ncol=1)\n",
    "\n",
    "# Adjust size and title\n",
    "width = 5.50107 / 0.8\n",
    "height = 8.02778 / (2.0)\n",
    "fig.set_size_inches(width, height)\n",
    "fig.suptitle('LinBreg with Nuclear Norm on FCC Layers', fontsize=10)\n",
    "\n",
    "# Adjust layout to make space for the legend\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.95])  # Adjust for legend space\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
