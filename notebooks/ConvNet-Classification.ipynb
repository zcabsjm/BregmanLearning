{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044d7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ------------------------\n",
    "# get up one directory \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "# ------------------------\n",
    "\n",
    "# custom packages\n",
    "import models.aux_funs as maf\n",
    "import optimizers as op\n",
    "import regularizers as reg\n",
    "import train\n",
    "import math\n",
    "import utils.configuration as cf\n",
    "import utils.datasets as ud\n",
    "from models.mnist_conv import mnist_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb1290",
   "metadata": {},
   "source": [
    "# Fix the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf73f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "cf.seed_torch(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1cf2a",
   "metadata": {},
   "source": [
    "# Configure the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3dd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_args = {#\n",
    "    # data specification\n",
    "    'data_file':\"../../datasets\",'train_split':0.95, 'data_set':\"Fashion-MNIST\", 'download':True,\n",
    "    # cuda\n",
    "    'use_cuda':False, 'num_workers':0, 'cuda_device':0, 'pin_memory':True, 'train_split':0.95,\n",
    "    #\n",
    "    'epochs':15,\n",
    "    # optimizer\n",
    "    'delta':1.0, 'lr':0.001, 'lamda_0':1e-4, 'lamda_1':.5, 'optim':\"LinBreg\", 'conv_group':True,\n",
    "    'beta':0.0,\n",
    "    # initialization\n",
    "    'sparse_init':0.01, 'r':[10.,10.,10.],\n",
    "    # misc\n",
    "    'random_seed':random_seed, 'eval_acc':True,\n",
    "}\n",
    "\n",
    "conf = cf.Conf(**conf_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24fc71",
   "metadata": {},
   "source": [
    "# Initiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2a15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {'mean':conf.data_set_mean, 'std':conf.data_set_std}    \n",
    "\n",
    "model = mnist_conv(**model_kwargs)\n",
    "best_model = train.best_model(mnist_conv(**model_kwargs).to(conf.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2696003",
   "metadata": {},
   "source": [
    "# Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e2e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {'mean':conf.data_set_mean, 'std':conf.data_set_std}    \n",
    "def init_weights(conf, model):\n",
    "    # sparsify\n",
    "    maf.sparse_bias_uniform_(model, 0,conf.r[0])\n",
    "    maf.sparse_bias_uniform_(model, 0,conf.r[0], ltype=torch.nn.Conv2d)\n",
    "    maf.sparse_weight_normal_(model, conf.r[1])\n",
    "    maf.sparse_weight_normal_(model, conf.r[2], ltype=torch.nn.Conv2d)\n",
    "    #\n",
    "    maf.sparsify_(model, conf.sparse_init, ltype = nn.Conv2d, conv_group=conf.conv_group)\n",
    "    maf.sparsify_(model, conf.sparse_init, ltype = nn.Linear)\n",
    "    model = model.to(conf.device)    \n",
    "    return model\n",
    "\n",
    "model = init_weights(conf,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff0a86b",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51048c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_opt(conf, model):\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # Get access to different model parameters\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    weights_conv = maf.get_weights_conv(model)\n",
    "    weights_linear = maf.get_weights_linear(model)\n",
    "    biases = maf.get_bias(model)\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # Initialize optimizer\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    if conf.conv_group:\n",
    "        reg2 = reg.reg_l1_l2_conv(lamda=conf.lamda_0)\n",
    "    else:\n",
    "        reg2 = reg.reg_l1(lamda=conf.lamda_0)\n",
    "    \n",
    "    if conf.optim == \"SGD\":\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=conf.lr, momentum=conf.beta)\n",
    "    elif conf.optim == \"LinBreg\": # change 'reg' to reg2 if want to use l1_l2 regularization as was previously\n",
    "        opt = op.LinBreg([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg.reg_nuclear_conv(lamda=conf.lamda_0), 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(lamda=conf.lamda_1), 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': biases, 'lr': conf.lr, 'momentum':conf.beta}])\n",
    "    elif conf.optim == \"ProxSGD\":\n",
    "        opt = op.ProxSGD([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg2, 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(lamda=conf.lamda_1), 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': biases, 'lr': conf.lr, 'momentum':conf.beta}])            \n",
    "    elif conf.optim == \"AdaBreg\":\n",
    "        opt = op.AdaBreg([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg.reg_nuclear_conv(lamda=conf.lamda_0),'delta':conf.delta},\n",
    "                           {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(lamda=conf.lamda_1),'delta':conf.delta},\n",
    "                           {'params': biases, 'lr': conf.lr}])\n",
    "    elif conf.optim == \"L1SGD\":\n",
    "        def weight_reg(model):\n",
    "            reg1 =  reg.reg_l1(lamda=conf.lamda_1)\n",
    "        \n",
    "            loss1 = reg1(model.layers2[0].weight) + reg1(model.layers2[2].weight)\n",
    "            loss2 = reg2(model.layers1[0].weight) + reg2(model.layers1[3].weight)\n",
    "            return loss1 + loss2\n",
    "        \n",
    "        conf.weight_reg = weight_reg\n",
    "        \n",
    "        opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=beta)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Optimizer specified\")\n",
    "\n",
    "    # learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=5,threshold=0.01)\n",
    "    \n",
    "    return opt, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9836a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53442c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = ud.get_data_set(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4ea23",
   "metadata": {},
   "source": [
    "# History and Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "985cdc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize history\n",
    "tracked = ['loss', 'node_sparse']\n",
    "train_hist = {}\n",
    "val_hist = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6adef",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d28eb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 0\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.18257894736842106\n",
      "Train Loss: 972.6276643276215\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.18566666666666667\n",
      "Non-zero kernels: 0.6889423076923077\n",
      "Linear sparsity: 0.009860070116054158\n",
      "Overall sparsity: 0.3086709653398321\n",
      "Node sparsity: [1.0, 0.5]\n",
      "Regularization values per group: [tensor(0.0066), 231.51193237304688, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.66\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 1\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.19210526315789472\n",
      "Train Loss: 905.1605406999588\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.18533333333333332\n",
      "Non-zero kernels: 0.6889423076923077\n",
      "Linear sparsity: 0.009852514506769825\n",
      "Overall sparsity: 0.30866673436230707\n",
      "Node sparsity: [1.0, 0.5]\n",
      "Regularization values per group: [tensor(0.0066), 231.67615842819214, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.6799999999999999\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 2\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.1920877192982456\n",
      "Train Loss: 875.6505506038666\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.18533333333333332\n",
      "Non-zero kernels: 0.6889423076923077\n",
      "Linear sparsity: 0.009852514506769825\n",
      "Overall sparsity: 0.30866673436230707\n",
      "Node sparsity: [1.0, 0.5]\n",
      "Regularization values per group: [tensor(0.0066), 231.82400798797607, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.7\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 3\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.2826315789473684\n",
      "Train Loss: 837.1037912368774\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.277\n",
      "Non-zero kernels: 0.7043269230769231\n",
      "Linear sparsity: 0.009867625725338492\n",
      "Overall sparsity: 0.31544476035743296\n",
      "Node sparsity: [1.0, 0.5]\n",
      "Regularization values per group: [tensor(0.0066), 232.05626773834229, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.7\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 4\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.38649122807017544\n",
      "Train Loss: 773.8863071203232\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.41533333333333333\n",
      "Non-zero kernels: 0.7043269230769231\n",
      "Linear sparsity: 0.009882736943907157\n",
      "Overall sparsity: 0.3154532223124831\n",
      "Node sparsity: [1.0, 0.6]\n",
      "Regularization values per group: [tensor(0.0066), 232.39074063301086, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 5\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.46171929824561403\n",
      "Train Loss: 713.0281533002853\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.474\n",
      "Non-zero kernels: 0.7043269230769231\n",
      "Linear sparsity: 0.00989029255319149\n",
      "Overall sparsity: 0.3154574532900081\n",
      "Node sparsity: [1.0, 0.6]\n",
      "Regularization values per group: [tensor(0.0067), 232.69213199615479, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 6\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.48140350877192983\n",
      "Train Loss: 671.7717485427856\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.48333333333333334\n",
      "Non-zero kernels: 0.7043269230769231\n",
      "Linear sparsity: 0.009905403771760154\n",
      "Overall sparsity: 0.31546591524505824\n",
      "Node sparsity: [1.0, 0.8]\n",
      "Regularization values per group: [tensor(0.0067), 232.95174074172974, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 7\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.5037368421052631\n",
      "Train Loss: 637.9405785799026\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.48533333333333334\n",
      "Non-zero kernels: 0.7043269230769231\n",
      "Linear sparsity: 0.009928070599613153\n",
      "Overall sparsity: 0.31547860817763335\n",
      "Node sparsity: [1.0, 0.9]\n",
      "Regularization values per group: [tensor(0.0067), 233.22989463806152, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 8\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.5590526315789474\n",
      "Train Loss: 590.0808498263359\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.6013333333333334\n",
      "Non-zero kernels: 0.7346153846153847\n",
      "Linear sparsity: 0.009958293036750483\n",
      "Overall sparsity: 0.32882311129163283\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [tensor(0.0067), 233.6375412940979, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 9\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.6255964912280702\n",
      "Train Loss: 515.370783507824\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.6303333333333333\n",
      "Non-zero kernels: 0.75\n",
      "Linear sparsity: 0.00997340425531915\n",
      "Overall sparsity: 0.3356011372867587\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [tensor(0.0067), 234.04811334609985, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 10\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.6411052631578947\n",
      "Train Loss: 462.53089076280594\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.6503333333333333\n",
      "Non-zero kernels: 0.7653846153846153\n",
      "Linear sparsity: 0.009988515473887814\n",
      "Overall sparsity: 0.34237916328188467\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [tensor(0.0067), 234.38320446014404, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 11\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.6508421052631579\n",
      "Train Loss: 431.05734860897064\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.6496666666666666\n",
      "Non-zero kernels: 0.7653846153846153\n",
      "Linear sparsity: 0.010011182301740812\n",
      "Overall sparsity: 0.3423918562144598\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [tensor(0.0067), 234.64824056625366, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 12\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.6809122807017544\n",
      "Train Loss: 406.77605414390564\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.694\n",
      "Non-zero kernels: 0.7802884615384615\n",
      "Linear sparsity: 0.010048960348162475\n",
      "Overall sparsity: 0.3489710262659085\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [tensor(0.0067), 234.97098636627197, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 13\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.7100175438596491\n",
      "Train Loss: 384.7295732498169\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.705\n",
      "Non-zero kernels: 0.7802884615384615\n",
      "Linear sparsity: 0.010071627176015474\n",
      "Overall sparsity: 0.34898371919848364\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [tensor(0.0067), 235.2596583366394, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "Epoch: 14\n",
      "--------------------------------------------------\n",
      "Train Accuracy: 0.7175438596491228\n",
      "Train Loss: 369.3150233030319\n",
      "--------------------------------------------------\n",
      "Validation Accuracy: 0.7086666666666667\n",
      "Non-zero kernels: 0.7802884615384615\n",
      "Linear sparsity: 0.010094294003868472\n",
      "Overall sparsity: 0.34899641213105875\n",
      "Node sparsity: [1.0, 1.0]\n",
      "Regularization values per group: [tensor(0.0067), 235.5133080482483, 0.0]\n",
      "Learning rate: 0.001\n",
      "Avg conv kernel rank ratio: 0.72\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# Reinit weigts and the corresponding optimizer\n",
    "# -----------------------------------------------------------------------------------\n",
    "model = init_weights(conf, model)\n",
    "opt, scheduler = init_opt(conf, model)\n",
    "# Adaptive lamda adjustment\n",
    "# -----------------------------------------------------------------------------------\n",
    "lamda = 0.01  # Initialize lamda to a larger value\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')\n",
    "epochs_since_improvement = 0\n",
    "minimum_lamda = 1e-6  # Minimum value for lamda\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# train the model\n",
    "# -----------------------------------------------------------------------------------\n",
    "for epoch in range(conf.epochs):\n",
    "    print(25*\"<>\")\n",
    "    print(50*\"|\")\n",
    "    print(25*\"<>\")\n",
    "    print('Epoch:', epoch)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # train step, log the accuracy and loss\n",
    "    # ------------------------------------------------------------------------\n",
    "    train_data = train.train_step(conf, model, opt, train_loader)\n",
    "\n",
    "    # update history\n",
    "    for key in tracked:\n",
    "        if key in train_data:\n",
    "            var_list = train_hist.setdefault(key, [])\n",
    "            var_list.append(train_data[key])           \n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # validation step\n",
    "    val_data = train.validation_step(conf, model, opt, valid_loader)\n",
    "    val_loss = val_data['loss']\n",
    "\n",
    "    # update validation history\n",
    "    for key in tracked:\n",
    "        if key in val_data:\n",
    "            var = val_data[key]\n",
    "            if isinstance(var, list):\n",
    "                for i, var_loc in enumerate(var):\n",
    "                    key_loc = key+\"_\" + str(i)\n",
    "                    var_list = val_hist.setdefault(key_loc, [])\n",
    "                    val_hist[key_loc].append(var_loc)\n",
    "            else:\n",
    "                var_list = val_hist.setdefault(key, [])\n",
    "                var_list.append(var)   \n",
    "\n",
    "\n",
    "    scheduler.step(train_data['loss'])\n",
    "    print(\"Learning rate:\",opt.param_groups[0]['lr'])\n",
    "    best_model(train_data['acc'], val_data['acc'], model=model)\n",
    "\n",
    "        # Adaptive λ (alpha) adjustment for convolutional layers only.\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_since_improvement = 0\n",
    "    else:\n",
    "        epochs_since_improvement += 1\n",
    "\n",
    "    if epochs_since_improvement > patience:\n",
    "        lamda = lamda / 2.0  # Reduce λ: this will allow more singular values (higher rank) later on\n",
    "        print(f\"Reducing conv layer lamda (α) to {lamda}\")\n",
    "\n",
    "        # Loop through optimizer parameter groups and update the nuclear norm regulariser for conv layers.\n",
    "        for param_group in opt.param_groups:\n",
    "            if 'reg' in param_group and isinstance(param_group['reg'], reg.reg_nuclear_conv):\n",
    "                param_group['reg'].lamda = lamda  # This λ is only for conv layers!\n",
    "        epochs_since_improvement = 0\n",
    "\n",
    "    lamda = max(lamda, minimum_lamda)  # Prevent λ from going to zero\n",
    "    conf.lamda_0 = lamda  # Update the global config value\n",
    "\n",
    "    ratio = maf.conv_effective_rank_ratio(model, epsilon=1e-3)\n",
    "    print(f\"Avg conv kernel rank ratio: {ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabbb46d-724c-4d45-a7b3-c5bfef8a3f03",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7c82a0-6940-4c33-bcb2-c4b2ab56171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Test Accuracy: 0.7143\n",
      "Linear sparsity: 0.010094294003868472\n",
      "Average Conv layer rank (ε=1e-3): 0.72\n"
     ]
    }
   ],
   "source": [
    "train.test(conf, best_model.best_model, test_loader) # this is for adabreg, as specifed in conf_args\n",
    "#print(f'Convolution kernel sparsity: {maf.conv_sparsity(best_model.best_model)}')\n",
    "print(f'Linear sparsity: {maf.linear_sparsity(best_model.best_model)}')\n",
    "rank_ratio = maf.conv_effective_rank_ratio(best_model.best_model, epsilon=1e-3)\n",
    "print(f'Average Conv layer rank (ε=1e-3): {rank_ratio}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
